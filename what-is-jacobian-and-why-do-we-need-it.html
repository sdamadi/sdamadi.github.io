<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>What is Jacobian matrix and why do we need it? - Saeed Damadi</title><meta name="robots" content="index, follow"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://sdamadi.github.io/what-is-jacobian-and-why-do-we-need-it.html"><link rel="amphtml" href="https://sdamadi.github.io/amp/what-is-jacobian-and-why-do-we-need-it.html"><link type="application/atom+xml" rel="alternate" href="https://sdamadi.github.io/feed.xml"><meta property="og:title" content="What is Jacobian matrix and why do we need it?"><meta property="og:site_name" content="My blog - Saeed Damadi"><meta property="og:description" content="Derivative of univariate functionTo understand what is Jacobian, we need to revisit the derivative of a univariate function wherein $f$ maps the real line into the real line, that is, $f: \mathbb{R} \rightarrow \mathbb{R} $. The derivative of $f$ denoted by $f'$ measures the sensitivity to change&hellip;"><meta property="og:url" content="https://sdamadi.github.io/what-is-jacobian-and-why-do-we-need-it.html"><meta property="og:type" content="article"><link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin><link href="https://fonts.googleapis.com/css?family=Roboto:400,700|Roboto+Condensed:400,700&amp;subset=latin-ext" rel="stylesheet"><link rel="stylesheet" href="https://sdamadi.github.io/assets/css/style.css?v=aa41620c4f80dc7a8874270e3bdddd5b"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://sdamadi.github.io/what-is-jacobian-and-why-do-we-need-it.html"},"headline":"What is Jacobian matrix and why do we need it?","datePublished":"2019-12-23T19:02","dateModified":"2019-12-23T21:31","description":"Derivative of univariate functionTo understand what is Jacobian, we need to revisit the derivative of a univariate function wherein $f$ maps the real line into the real line, that is, $f: \\mathbb{R} \\rightarrow \\mathbb{R} $. The derivative of $f$ denoted by $f'$ measures the sensitivity to change&hellip;","author":{"@type":"Person","name":"Saeed"},"publisher":{"@type":"Organization","name":"Saeed"}}</script><script async src="https://sdamadi.github.io/assets/js/lazysizes.min.js?v=dc4b666bb3324aea4ead22e26059c761"></script><style>.top__search [type=search] {
						background-image: url(https://sdamadi.github.io/assets/svg/search.svg);
				    }</style><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script></head><body><div class="container"><header class="js-top is-sticky"><a class="logo" href="https://sdamadi.github.io">Saeed Damadi</a><div class="top"><nav class="navbar js-navbar"><button class="navbar__toggle js-navbar__toggle">Menu</button><ul class="navbar__menu"></ul></nav><div class="top__search"><form action="https://sdamadi.github.io/search.html" class="search"><input type="search" name="q" placeholder="search..."></form></div></div></header><main><article class="post"><div class="hero"><header class="hero__text"><h1>What is Jacobian matrix and why do we need it?</h1><p class="post__meta"><time datetime="2019-12-23T19:02">December 23, 2019 </time>By <a href="https://sdamadi.github.io/authors/saeed/" rel="author" title="Saeed">Saeed</a></p></header></div><div class="post__entry"><h3>Derivative of univariate function</h3><p>To understand what is Jacobian, we need to revisit the derivative of a univariate function wherein $f$ maps the real line into the real line, that is, $f: \mathbb{R} \rightarrow \mathbb{R} $. The derivative of $f$ denoted by $f'$ measures the sensitivity to change of the function value (output value, $f(x)$) with respect to a change in its argument (input value, $x$). Now the question is how we can measure the change of a function whose inputs is a vector in $\mathbb{R}^n$. From this point on we will focus on the change in a value of a function and try to associate it to the derivative of a univariate function.</p><p><strong>Note</strong>: $f'$ is also denoted by $\frac{df}{dx}$ which is read as the derivative of $f$ with respect to $x$. Here we have used $d$ since there is no other variables that derivative is being taken with respect to them.</p><p><strong>Remark: </strong>If $x$ becomes a number in real line instead of a vector, the gradient becomes the derivative which was expected.</p><h3>The gradient of a real-valued function</h3><p>When $f$ takes on a vector $x \in \mathbb{R}^n$ where $x = [x_1, x_2, \cdots,x_n]^{\top}$ and maps it to a number on the real line, we write $f : \mathbb{R}^n \rightarrow \mathbb{R}$. Since we have the ability to play with each coordinate of $x$ to change the value of the function, the concept of gradient comes into the picture. The gradient is a vector with the same length of $x$ and each coordinate shows the change in the value of $f$ when the corresponding coordinate changes. Therefore, we write</p><p> \begin{equation}<br>\nabla f = [\frac{\partial f}{\partial x_1}, \frac{\partial f}{\partial x_2}, \cdots, \frac{\partial f}{\partial x_n}]^{\top}<br>\end{equation}</p><p>Here we use $\nabla$ (nabla) symbol to suppress the right hand side when we want to address all the changes along $n$ directions. Also, $\partial$ is used to clarify that other than (let's say $x_1$), there are other variables whose change can affect the value of $f$.</p><h3>Jacobian of a vector-valued function</h3><p>Now let's get back to the question that I asked in the page title. You might say, "well, Jacobian matrix should be something that somehow connects to the change of a vector-valued function which takes a vector as its input". Yes correct! But how we do we write it?</p><p>First notice that we have $f$ where $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$, that is:</p><p>$$<br>f(x)=f(x_1, x_2, \cdots,x_n)= \begin{bmatrix}<br>f_1(x_1, x_2, \cdots,x_n)\\ f_2(x_1, x_2, \cdots,x_n)\\ \vdots \\ f_n(x_1, x_2, \cdots,x_n)<br>\end{bmatrix}<br>$$</p><p>As you can see the value of each function $f_i$ where $i= 1, 2, \cdots, m$ can vary when one of $x_j$'s changes. This is where Jacobian matrix comes into the picture. It is defined as the following:</p><p>$$<br>J_f(x)= \begin{bmatrix}<br>\frac{\partial f_1}{\partial x_1} &amp; \frac{\partial f_1}{\partial x_2}&amp; \cdots&amp; \frac{\partial f_1}{\partial x_n}\\<br>\frac{\partial f_2}{\partial x_1} &amp; \frac{\partial f_2}{\partial x_2}&amp; \cdots&amp; \frac{\partial f_2}{\partial x_n}\\<br>\vdots &amp; \vdots &amp; \cdots &amp; \vdots\\<br>\frac{\partial f_m}{\partial x_1} &amp; \frac{\partial f_m}{\partial x_2}&amp; \cdots&amp; \frac{\partial f_m}{\partial x_n}<br>\end{bmatrix}<br>=<br>\begin{bmatrix}<br>\nabla^{\top} f_1\\<br>\nabla^{\top} f_2\\<br>\vdots\\<br>\nabla^{\top} f_n\\<br>\end{bmatrix}<br>$$</p><p>By looking at $i$-th row of the Jacobian matrix, we see that it is transpose of the gradient of $f_i$, i.e., $(\nabla f_i)^{\top}$ which I denoted by $\nabla^{\top} f_i$ . </p><p><strong>Remark 1</strong>: If $f$ becomes a scalar-valued function and $x$ becomes a number in real line instead of a vector, the Jacobian matrix becomes the derivative!</p><p><strong>Remark 2</strong>: Jacobian matrix is the matrix of all first-order partial derivatives of the function.</p><h3>Why do we need Jacobian matrix?</h3><p>Jacobian of a composition function is the product of the Jacobian matrices of each functions. Suppose we have the following fucntion:</p><p>$$<br>f (x)= f_1(f_2(\cdots( f_n(x) ) ) = f_1 \circ f_2 \circ \cdots\circ f_n(x)<br>$$</p><p>The Jacobian matrix of $f$ with respect to $x$ is:</p><p>$$<br>J_f = J_{f_1} \cdot J_{f_2} \cdots J_{f_n}(x)<br>$$</p><p>However, there is a big caveat here; in order to find Jacobian matrix of $f$, we need to find all other Jacobian matrices. We know Jacobian matrix is all first-order partial derivatives of the vector-valued function with respect to its variable. But what is the variable of, let's say $f_1$? The variable of $f_1$ is the f but $f_1$, i.e., $f_2(f_3(\cdots( f_n(x) ) ) = f_2 \circ f_3 \circ \cdots\circ f_n(x)$. </p><p><a href="https://sdamadi.github.io/jacobian-of-a-composition-function.html">In this post</a> I will go through an example and clarify all those abstract concepts that were discussed in the last paragraph.</p><p class="post__last-updated">This article was updated on December 23, 2019</p></div><aside class="post__share"></aside><footer class="post__footer"><div class="post__bio"><h3><a href="https://sdamadi.github.io/authors/saeed/" class="inverse" title="Saeed">Saeed</a></h3></div><nav class="post__nav"><div class="post__nav__prev">Previous Post<h5><a href="https://sdamadi.github.io/jacobian-of-a-composition-function.html" class="inverse" rel="prev">Jacobian matrix of a composition function</a></h5></div></nav><div class="post__related"><h3>Related posts</h3><div class="post__related__wrap"><figure><figcaption><h4><a href="https://sdamadi.github.io/jacobian-of-a-composition-function.html" class="inverse">Jacobian matrix of a composition function</a></h4><time datetime="2019-12-23T17:58">December 23, 2019</time></figcaption></figure></div></div></footer></article></main><footer class="footer"><div class="footer__copyright">Powered by Publii</div></footer></div><script defer="defer" src="https://sdamadi.github.io/assets/js/jquery-3.2.1.slim.min.js?v=f307ecc7f6353949f03c06ffa70652a2"></script><script defer="defer" src="https://sdamadi.github.io/assets/js/scripts.min.js?v=f37607af05f83050cdcc37ea18bb5ee1"></script></body></html>