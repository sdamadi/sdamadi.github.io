<!DOCTYPE html><html lang="en"><head><meta charset="utf-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1"><title>What is Jacobian matrix of $f(x)&#x3D; Ax$? - Saeed Damadi</title><meta name="description" content="In this short post we are going to find the Jacobian matrix of $f(x)= Ax$ where $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$, $x \in \mathbb{R}^n$, and $A \in \mathbb{R}^{m \times n}$. As I explained here, in order to find the Jacobian matrix we need a vector-valued function&hellip;"><meta name="robots" content="index, follow"><meta name="generator" content="Publii Open-Source CMS for Static Site"><link rel="canonical" href="https://sdamadi.github.io/what-is-jacobian-matrix-of-dollarfx-axdollar.html"><link rel="amphtml" href="https://sdamadi.github.io/amp/what-is-jacobian-matrix-of-dollarfx-axdollar.html"><link rel="alternate" type="application/atom+xml" href="https://sdamadi.github.io/feed.xml"><link rel="alternate" type="application/json" href="https://sdamadi.github.io/feed.json"><meta property="og:title" content="What is Jacobian matrix of $f(x)= Ax$?"><meta property="og:site_name" content="My blog - Saeed Damadi"><meta property="og:description" content="In this short post we are going to find the Jacobian matrix of $f(x)= Ax$ where $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$, $x \in \mathbb{R}^n$, and $A \in \mathbb{R}^{m \times n}$. As I explained here, in order to find the Jacobian matrix we need a vector-valued function&hellip;"><meta property="og:url" content="https://sdamadi.github.io/what-is-jacobian-matrix-of-dollarfx-axdollar.html"><meta property="og:type" content="article"><link rel="preconnect" href="https://fonts.gstatic.com/" crossorigin><link href="https://fonts.googleapis.com/css?family=Roboto:400,500&amp;subset=latin-ext" rel="stylesheet"><link rel="stylesheet" href="https://sdamadi.github.io/assets/css/style.css?v=b51349db1483749b4e0ec880159fc912"><script type="application/ld+json">{"@context":"http://schema.org","@type":"Article","mainEntityOfPage":{"@type":"WebPage","@id":"https://sdamadi.github.io/what-is-jacobian-matrix-of-dollarfx-axdollar.html"},"headline":"What is Jacobian matrix of $f(x)= Ax$?","datePublished":"2019-12-25T14:54","dateModified":"2019-12-25T17:55","description":"In this short post we are going to find the Jacobian matrix of $f(x)= Ax$ where $f: \\mathbb{R}^n \\rightarrow \\mathbb{R}^m$, $x \\in \\mathbb{R}^n$, and $A \\in \\mathbb{R}^{m \\times n}$. As I explained here, in order to find the Jacobian matrix we need a vector-valued function&hellip;","author":{"@type":"Person","name":"S. M. Saeed Damadi"},"publisher":{"@type":"Organization","name":"S. M. Saeed Damadi"}}</script><script async src="https://sdamadi.github.io/assets/js/lazysizes.min.js?v=dc4b666bb3324aea4ead22e26059c761"></script><style>.infobar__search [type="search"] {
	                     background-image: url(https://sdamadi.github.io/assets/svg/search.svg);
	                 }</style><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
      inlineMath: [ ['$','$'], ["\\(","\\)"] ],
      processEscapes: true
    }
  });</script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML" async></script></head><body><header class="topbar js-top is-sticky"><div class="topbar__inner"><a class="logo" href="https://sdamadi.github.io/">Saeed Damadi</a><nav class="navbar js-navbar"><button class="navbar__toggle js-navbar__toggle">Menu</button><ul class="navbar__menu"></ul></nav></div></header><div class="content"><div class="infobar"><div class="infobar__update">Last Updated: <time datetime="2021-02-17T01:36">February 17, 2021</time></div><div class="infobar__search"><form action="https://sdamadi.github.io/search.html"><input type="search" name="q" placeholder=" search..."></form></div></div><main class="main"><article class="post"><header class="u-header post__header"><h1>What is Jacobian matrix of $f(x)&#x3D; Ax$?</h1><div class="u-header__meta u-small"><div><a href="https://sdamadi.github.io/authors/saeed/" title="S. M. Saeed Damadi">S. M. Saeed Damadi</a> <time datetime="2019-12-25T14:54">December 25, 2019</time></div></div></header><div class="post__entry u-inner"><p>In this short post we are going to find the Jacobian matrix of $f(x)= Ax$ where $f: \mathbb{R}^n \rightarrow \mathbb{R}^m$, $x \in \mathbb{R}^n$, and $A \in \mathbb{R}^{m \times n}$.</p><h3>Why this function is so important?</h3><ol><li>It is a linear function</li><li>It appers in neural networks when we want to find <a href="https://sdamadi.github.io/compute-the-gradient-of-neural-network-loss-function.html">the loss function</a></li><li>It generalize $f(x)= ax$ where $x$, and $a$ are scalars.</li></ol><p><a href="https://sdamadi.github.io/what-is-jacobian-and-why-do-we-need-it.html#mcetoc_1dsqmf85h2">As I explained here</a>, in order to find the Jacobian matrix we need a vector-valued function which we have but one should be able to represent each coordinte of $f$ as a function so we do the following:</p><p>$$<br>\begin{align}<br>f(x)&amp;= Ax =<br>\begin{bmatrix}<br>A_{1\bullet}\\<br>A_{2\bullet}\\<br>\vdots\\<br>A_{m\bullet}\\<br>\end{bmatrix}<br>x<br>=<br>\begin{bmatrix}<br>A_{1\bullet}x\\<br>A_{2\bullet}x\\<br>\vdots\\<br>A_{m\bullet}x\\<br>\end{bmatrix}=<br>\begin{bmatrix}<br>f_1(x)\\<br>f_2(x)\\<br>\vdots\\<br>f_n(x)\\<br>\end{bmatrix}\\<br>&amp;=<br>\begin{bmatrix}<br>a_{11}x_1 + a_{12}x_2 + \cdots + a_{1n}x_n\\<br>a_{21}x_1 + a_{22}x_2 + \cdots + a_{2n}x_n\\<br>\vdots\\<br>a_{m1}x_1 + a_{m2}x_2 + \cdots + a_{mn}x_nx\\<br>\end{bmatrix}\\<br>\end{align}<br>$$</p><p>where $A_{i\bullet}$ is the $i$-th row of $A$ and $x = [x_1, x_2, \cdots, x_n]^{\top}$.<br>Hence according to what we discussed <a href="https://sdamadi.github.io/what-is-jacobian-and-why-do-we-need-it.html">in the other post</a>,<br>$$<br>J_f(x) = \begin{bmatrix}<br>a_{11} &amp; a_{12} &amp; \cdots &amp; a_{1n}\\<br>a_{21} &amp; a_{22} &amp; \cdots &amp; a_{2n}\\<br>\vdots &amp; \vdots &amp; \cdots &amp; \vdots\\<br>a_{m1} &amp; a_{m2} &amp; \cdots &amp; a_{mn}\\<br>\end{bmatrix}<br>=A<br>$$</p><p><strong>Note</strong>: It does not make any differences if we add a constant vector $b$ to $Ax$, i.e., $f(x) = Ax + b$.</p></div><aside class="post__aside"><div class="post__last-updated u-small">This article was updated on December 25, 2019</div><div class="post__share"></div></aside><footer class="post__footer"><div class="post__bio u-author box"><div><h4 class="u-author__name"><a href="https://sdamadi.github.io/authors/saeed/" title="S. M. Saeed Damadi">S. M. Saeed Damadi</a></h4></div></div><nav class="post__nav box"><div class="post__nav__prev"><a href="https://sdamadi.github.io/what-is-jacobian-and-why-do-we-need-it.html" class="post__nav__link" rel="prev"><div class="u-small">Previous Post<h5>What is Jacobian matrix and why do we need it?</h5></div></a></div><div class="post__nav__next"><a href="https://sdamadi.github.io/compute-the-gradient-of-neural-network-loss-function.html" class="post__nav__link" rel="next"><div class="u-small">Next Post<h5>Compute the gradient of a neural network</h5></div></a></div></nav><div class="post__related box"><h3 class="box__title">Related posts</h3><div class="post__related__wrap"><figure><figcaption><h4><a href="https://sdamadi.github.io/linear-neural-network-to-creat-dollarfx-wtopxbdollar.html" class="inverse">Creating nonlinear neural network and finding the Jacobian matrix of its funciton</a></h4><time datetime="2019-12-25T20:12" class="u-small">December 25, 2019</time></figcaption></figure><figure><figcaption><h4><a href="https://sdamadi.github.io/how-to-use-linear-nn-to.html" class="inverse">Linear neural network to creat $f(x)&#x3D; W^{\top}x$</a></h4><time datetime="2019-12-25T17:57" class="u-small">December 25, 2019</time></figcaption></figure><figure><figcaption><h4><a href="https://sdamadi.github.io/what-is-jacobian-and-why-do-we-need-it.html" class="inverse">What is Jacobian matrix and why do we need it?</a></h4><time datetime="2019-12-23T19:02" class="u-small">December 23, 2019</time></figcaption></figure></div></div></footer></article></main><div class="sidebar"><section class="box"><h3 class="box__title">Authors</h3><ul class="authors"><li><a href="https://sdamadi.github.io/authors/saeed/"><img data-src="" class="lazyload authors__img" alt="S. M. Saeed Damadi"></a><div><a href="https://sdamadi.github.io/authors/saeed/" class="authors__title">S. M. Saeed Damadi</a> <span class="u-small">Post: 6</span></div></li></ul></section><section class="newsletter box box--gray"><h3 class="box__title">Newsletter</h3><p class="newsletter__description">Sign up to receive email updates and to hear what's going on with us!</p><form>...</form></section></div><footer class="footer"><a class="footer__logo" href="https://sdamadi.github.io/">Saeed Damadi</a><nav><ul class="footer__nav"></ul></nav><div class="footer__copyright">Powered by Publii</div></footer></div><script defer="defer" src="https://sdamadi.github.io/assets/js/jquery-3.2.1.slim.min.js?v=f307ecc7f6353949f03c06ffa70652a2"></script><script defer="defer" src="https://sdamadi.github.io/assets/js/scripts.min.js?v=07b53ae91f8045eab042a695e4a26034"></script></body></html>